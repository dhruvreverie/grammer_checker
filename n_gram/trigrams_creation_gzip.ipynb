{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcd47bc-ac43-481b-9206-ba28a8755f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruv/grammer_checker/venv_grammer_check/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import multiprocessing\n",
    "import json\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "from optimum.onnxruntime import ORTModelForTokenClassification\n",
    "import concurrent.futures\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "\n",
    "# Load the ONNX model for NER Classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/dhruv/NER/git/models/onnx_muril_model\")\n",
    "model = ORTModelForTokenClassification.from_pretrained('/home/dhruv/NER/git/models/onnx_muril_model')\n",
    "\n",
    "\n",
    "ner_pipeline = pipeline('token-classification', model=model, tokenizer=tokenizer, aggregation_strategy='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787912f-b1c0-4926-b5ec-68bb573cef10",
   "metadata": {},
   "source": [
    "# Reading the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d668b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name= 'combining_hindi_error_wiki'\n",
    "#combining_hindi_error_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a014ab-61cb-4ba2-9f97-466c0ae2aa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>महादेव  बानी के रूप में और बाद में रियलि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>यह जर्मन दार्शनिक मार्टिन हाइडेगर के अस्त...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Correct\n",
       "0        महादेव  बानी के रूप में और बाद में रियलि...\n",
       "1       यह जर्मन दार्शनिक मार्टिन हाइडेगर के अस्त..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(f\"trigram_data/{file_name}.csv\")\n",
    "df1 = pd.read_csv(f\"../{file_name}.csv\")\n",
    "df1 = df1[['Correct']]\n",
    "df1.shape\n",
    "# df = df[0:15001]\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99fa224f-5c24-4340-8822-4548ab6324c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Correct'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d7b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1[500001:800001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f01e278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500001</th>\n",
       "      <td>डीसीडब्ल्यू ने सात महाविद्यालयों को नोटिस जारी...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500002</th>\n",
       "      <td>डीसीपी अधिकारी, रंजन चित्तौड़ा अपने गुरु के हत...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500003</th>\n",
       "      <td>डीसीपी को ये सारी बात पता होती है, पर वो इसके ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500004</th>\n",
       "      <td>डीसीबी 1988 में आठ जर्मन क्रिकेट क्लबों द्वारा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500005</th>\n",
       "      <td>डीसूजा ने 1953 में पहले अंतर्राष्ट्रीय महिला ह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>यही भावों का विरेचन है और कविता का यही वास्तवि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>यही भाषा का सामान्य ज्ञान कहलाता है.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>यही भेद आज के सौलिसिटर तथा ऐडवोकेट में है.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>यही भौम सूर्य के परिक्रमा करते ग्रहों में मंगल...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>यही मंगल दिवस गोपाष्टमी कहलाता है.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Correct\n",
       "500001  डीसीडब्ल्यू ने सात महाविद्यालयों को नोटिस जारी...\n",
       "500002  डीसीपी अधिकारी, रंजन चित्तौड़ा अपने गुरु के हत...\n",
       "500003  डीसीपी को ये सारी बात पता होती है, पर वो इसके ...\n",
       "500004  डीसीबी 1988 में आठ जर्मन क्रिकेट क्लबों द्वारा...\n",
       "500005  डीसूजा ने 1953 में पहले अंतर्राष्ट्रीय महिला ह...\n",
       "...                                                   ...\n",
       "799996  यही भावों का विरेचन है और कविता का यही वास्तवि...\n",
       "799997               यही भाषा का सामान्य ज्ञान कहलाता है.\n",
       "799998         यही भेद आज के सौलिसिटर तथा ऐडवोकेट में है.\n",
       "799999  यही भौम सूर्य के परिक्रमा करते ग्रहों में मंगल...\n",
       "800000                 यही मंगल दिवस गोपाष्टमी कहलाता है.\n",
       "\n",
       "[300000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103767f-ffc3-4273-b735-8f6f9fdd6da8",
   "metadata": {},
   "source": [
    "### Preprocessing the datframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de62cce3-e0f2-496a-a4f2-60cf8c4a30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_hindi(data, column_name):\n",
    "    # New column for processed text\n",
    "    new_column = 'pre_processed_sentence'\n",
    "    \n",
    "    # Create a copy of the original column to avoid modifying the original data\n",
    "    data[new_column] = data[column_name]\n",
    "\n",
    "    # Remove URLs (both http(s) and www)\n",
    "    data[new_column] = data[new_column].str.replace(r'(https?://\\S+|www\\.\\S+)', ' ', regex=True)\n",
    "    print(\"Removed URLs\")\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    data[new_column] = data[new_column].str.replace(r'<.*?>', ' ', regex=True)\n",
    "    print(\"Removed HTML Tags\")\n",
    "    \n",
    "    # Remove newline, carriage return, and tab characters by replacing them with space\n",
    "    data[new_column] = data[new_column].str.replace(r'[\\n\\r\\t]', ' ', regex=True)\n",
    "    print(\"Removed tabs and new lines\")\n",
    "    \n",
    "    # Define Hindi characters and punctuation pattern to keep\n",
    "    hindi_pattern = r'[\\u0900-\\u097F\\u0020\\u0964\\u0965\\u0966-\\u096F]'\n",
    "    \n",
    "    # Retain only Hindi characters and the specified punctuation\n",
    "    data[new_column] = data[new_column].str.findall(hindi_pattern).str.join('')\n",
    "    print(\"Kept only Hindi characters and specified punctuation\")\n",
    "    \n",
    "    # Remove extra spaces and trim leading/trailing whitespace\n",
    "    data[new_column] = data[new_column].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    print(\"Removed extra spaces\")\n",
    "    \n",
    "    # Drop rows with missing values in the new column and duplicates\n",
    "    data.dropna(subset=[new_column], inplace=True)\n",
    "    data.drop_duplicates(subset=[new_column], inplace=True)\n",
    "    \n",
    "    # Reset index\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2dc154-d1f3-4084-a74b-b2d0a1f9722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_553358/943858414.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_column] = data[column_name].copy()\n",
      "/tmp/ipykernel_553358/943858414.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_column] = data[new_column].apply(lambda x: re.sub(r'(https|http)?:\\/\\/\\S+|www\\.\\S+', ' ', str(x)))\n",
      "/tmp/ipykernel_553358/943858414.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_column] = data[new_column].apply(lambda x: re.sub(r'<.*?>', ' ', str(x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed URLs\n",
      "Removed HTML Tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_553358/943858414.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_column] = data[new_column].apply(lambda x: re.sub(r'[\\n\\r\\t]', ' ', str(x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed tabs and new lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_553358/943858414.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_column] = data[new_column].apply(lambda x: ''.join(re.findall(hindi_pattern, str(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept only Hindi characters and specified punctuation\n",
      "Removed extra spaces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_553358/943858414.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_column] = data[new_column].apply(lambda x: re.sub(r'\\s+', ' ', str(x)).strip())\n",
      "/tmp/ipykernel_553358/943858414.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(subset=[new_column], inplace=True)\n",
      "/tmp/ipykernel_553358/943858414.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop_duplicates(subset=[new_column], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct</th>\n",
       "      <th>pre_process_correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>डीसीडब्ल्यू ने सात महाविद्यालयों को नोटिस जारी...</td>\n",
       "      <td>डीसीडब्ल्यू ने सात महाविद्यालयों को नोटिस जारी...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>डीसीपी अधिकारी, रंजन चित्तौड़ा अपने गुरु के हत...</td>\n",
       "      <td>डीसीपी अधिकारी रंजन चित्तौड़ा अपने गुरु के हत्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>डीसीपी को ये सारी बात पता होती है, पर वो इसके ...</td>\n",
       "      <td>डीसीपी को ये सारी बात पता होती है पर वो इसके क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>डीसीबी 1988 में आठ जर्मन क्रिकेट क्लबों द्वारा...</td>\n",
       "      <td>डीसीबी में आठ जर्मन क्रिकेट क्लबों द्वारा हस्त...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>डीसूजा ने 1953 में पहले अंतर्राष्ट्रीय महिला ह...</td>\n",
       "      <td>डीसूजा ने में पहले अंतर्राष्ट्रीय महिला हॉकी ट...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299145</th>\n",
       "      <td>यही भावों का विरेचन है और कविता का यही वास्तवि...</td>\n",
       "      <td>यही भावों का विरेचन है और कविता का यही वास्तवि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299146</th>\n",
       "      <td>यही भाषा का सामान्य ज्ञान कहलाता है.</td>\n",
       "      <td>यही भाषा का सामान्य ज्ञान कहलाता है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299147</th>\n",
       "      <td>यही भेद आज के सौलिसिटर तथा ऐडवोकेट में है.</td>\n",
       "      <td>यही भेद आज के सौलिसिटर तथा ऐडवोकेट में है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299148</th>\n",
       "      <td>यही भौम सूर्य के परिक्रमा करते ग्रहों में मंगल...</td>\n",
       "      <td>यही भौम सूर्य के परिक्रमा करते ग्रहों में मंगल...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299149</th>\n",
       "      <td>यही मंगल दिवस गोपाष्टमी कहलाता है.</td>\n",
       "      <td>यही मंगल दिवस गोपाष्टमी कहलाता है</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Correct  \\\n",
       "0       डीसीडब्ल्यू ने सात महाविद्यालयों को नोटिस जारी...   \n",
       "1       डीसीपी अधिकारी, रंजन चित्तौड़ा अपने गुरु के हत...   \n",
       "2       डीसीपी को ये सारी बात पता होती है, पर वो इसके ...   \n",
       "3       डीसीबी 1988 में आठ जर्मन क्रिकेट क्लबों द्वारा...   \n",
       "4       डीसूजा ने 1953 में पहले अंतर्राष्ट्रीय महिला ह...   \n",
       "...                                                   ...   \n",
       "299145  यही भावों का विरेचन है और कविता का यही वास्तवि...   \n",
       "299146               यही भाषा का सामान्य ज्ञान कहलाता है.   \n",
       "299147         यही भेद आज के सौलिसिटर तथा ऐडवोकेट में है.   \n",
       "299148  यही भौम सूर्य के परिक्रमा करते ग्रहों में मंगल...   \n",
       "299149                 यही मंगल दिवस गोपाष्टमी कहलाता है.   \n",
       "\n",
       "                             pre_process_correct_sentence  \n",
       "0       डीसीडब्ल्यू ने सात महाविद्यालयों को नोटिस जारी...  \n",
       "1       डीसीपी अधिकारी रंजन चित्तौड़ा अपने गुरु के हत्...  \n",
       "2       डीसीपी को ये सारी बात पता होती है पर वो इसके क...  \n",
       "3       डीसीबी में आठ जर्मन क्रिकेट क्लबों द्वारा हस्त...  \n",
       "4       डीसूजा ने में पहले अंतर्राष्ट्रीय महिला हॉकी ट...  \n",
       "...                                                   ...  \n",
       "299145  यही भावों का विरेचन है और कविता का यही वास्तवि...  \n",
       "299146                यही भाषा का सामान्य ज्ञान कहलाता है  \n",
       "299147          यही भेद आज के सौलिसिटर तथा ऐडवोकेट में है  \n",
       "299148  यही भौम सूर्य के परिक्रमा करते ग्रहों में मंगल...  \n",
       "299149                  यही मंगल दिवस गोपाष्टमी कहलाता है  \n",
       "\n",
       "[299150 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_hindi(df, 'Correct')#'correct_sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26057f3a-193c-4416-b9da-90e3c500a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the rows where the length is less than 3\n",
    "df = df[df['pre_process_correct_sentence'].apply(lambda x: len(x.split()) >= 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1396892-d4bd-4e67-9b81-71c2b59a6883",
   "metadata": {},
   "source": [
    "### Masking the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ecb8f9-e0fd-4890-b2c2-dd1059d0f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to get the predictions\n",
    "def get_predictions(sentence):\n",
    "    \"\"\"\n",
    "    Process a single sentence and replace named entities with 'MASK'.\n",
    "    \n",
    "    :param sentence: A string containing the sentence to process\n",
    "    :return: A string with named entities replaced by 'MASK'\n",
    "    \"\"\"\n",
    "    # Process the sentence using the NER pipeline\n",
    "    entities = ner_pipeline(sentence)\n",
    "    \n",
    "    # Create masked sentence\n",
    "    masked_sentence = sentence\n",
    "    for item in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
    "        start, end = item['start'], item['end']\n",
    "        masked_sentence = masked_sentence[:start] + \"MASK\" + masked_sentence[end:]\n",
    "    \n",
    "    return masked_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26daebb-bbb3-4c50-8048-33862da49087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    return get_predictions(row['pre_process_correct_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7624af52-b8d6-4270-ae8a-e76a2f95873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299150/299150 [1:25:57<00:00, 58.01it/s]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Get the number of CPUs and set the number of workers to use\n",
    "    num_cpus = os.cpu_count()\n",
    "    num_workers = int(num_cpus * 0.8)\n",
    "    \n",
    "    # Apply the function to the DataFrame using multiprocessing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Create a progress bar\n",
    "        tqdm.pandas(desc=\"Processing\")\n",
    "        \n",
    "        # Apply the function to each row in parallel\n",
    "        df['Masked_sentence'] = list(tqdm(executor.map(process_row, [row for _, row in df.iterrows()]), total=len(df)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0319b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = df[['pre_process_correct_sentence', 'Masked_sentence']]\n",
    "df_ner.to_csv(f'pre_processed_mask_data/{file_name}_5l_8l.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f4483-fb7f-404a-9f5c-98ca75b12a28",
   "metadata": {},
   "source": [
    "### Generate trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dce1acb-1d51-4711-8482-08d266afcb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(text, word_to_combine):\n",
    "    try:\n",
    "        words = text.split()\n",
    "        output = []\n",
    "        for i in range(len(words)- word_to_combine+1):\n",
    "            output.append(tuple(words[i:i+word_to_combine]))\n",
    "        return output\n",
    "    except TypeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc309088-24dc-47ed-89c3-a7aeea667e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 299150/299150 [00:01<00:00, 269262.43it/s]\n"
     ]
    }
   ],
   "source": [
    "df['trigrams'] = df['Masked_sentence'].progress_apply(lambda x: generate_trigrams(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85fc2e8f-734d-416d-a0a8-ff1bcca6e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_list = df['trigrams'].tolist()\n",
    "flattened_list = list({item for sublist in trigram_list for item in sublist})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf08495-7904-4c16-9cc2-74c8ae2dadc8",
   "metadata": {},
   "source": [
    "## Saving the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc3b703-3ad3-4e4c-a77a-079e600a5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert list of tuples to list of lists\n",
    "# data_list_of_lists = [list(item) for item in flattened_list]\n",
    "\n",
    "# # Define the file path\n",
    "# file_path = 'data.json'\n",
    "\n",
    "# # Write the list of lists to a JSON file\n",
    "# with open(file_path, 'w') as json_file:\n",
    "#     json.dump(data_list_of_lists, json_file)\n",
    "\n",
    "# print(f'Data has been saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8cc0cde-0047-4ba4-9764-c4708fbe8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to read the JSON file\n",
    "# def read_json(file_path):\n",
    "#     try:\n",
    "#         with open(file_path, 'r') as json_file:\n",
    "#             data_list_of_lists = json.load(json_file)\n",
    "#         return [tuple(item) for item in data_list_of_lists]\n",
    "#     except FileNotFoundError:\n",
    "#         return []\n",
    "\n",
    "# # Function to write data to the JSON file\n",
    "# def write_json(file_path, data):\n",
    "#     data_list_of_lists = [list(item) for item in data]\n",
    "#     with open(file_path, 'w') as json_file:\n",
    "#         json.dump(data_list_of_lists, json_file)\n",
    "\n",
    "# # Function to append new data to the JSON file\n",
    "# def append_to_json(file_path, new_data):\n",
    "#     # Read existing data\n",
    "#     data = read_json(file_path)\n",
    "    \n",
    "#     # Append new data (if it's not already present)\n",
    "#     for item in tqdm(new_data):\n",
    "#         if item not in data:\n",
    "#             data.append(item)\n",
    "    \n",
    "#     # Write the updated data back to the JSON file\n",
    "#     write_json(file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "561ceee3-c6d8-4f6b-9fc0-fb76d62b5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc5f8be-186c-43bb-9771-2f20f858b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Append new data to the JSON file\n",
    "# append_to_json(file_path, flattened_list)\n",
    "\n",
    "# print(f'New data has been appended to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d3adbcc-e3ff-4c6a-a6db-420561dcf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_json(file_path):\n",
    "#     try:\n",
    "#         with open(file_path, 'r') as json_file:\n",
    "#             data_list_of_lists = json.load(json_file)\n",
    "#         return [tuple(item) for item in data_list_of_lists]\n",
    "#     except FileNotFoundError:\n",
    "#         return []\n",
    "\n",
    "# def write_json(file_path, data):\n",
    "#     data_list_of_lists = [list(item) for item in data]\n",
    "#     with open(file_path, 'w') as json_file:\n",
    "#         json.dump(data_list_of_lists, json_file)\n",
    "\n",
    "# def process_chunk(args):\n",
    "#     chunk, existing_data = args\n",
    "#     return [item for item in chunk if item not in existing_data]\n",
    "\n",
    "# def append_to_json(file_path, new_data):\n",
    "#     # Read existing data\n",
    "#     existing_data = set(read_json(file_path))\n",
    "    \n",
    "#     # Determine the number of CPU cores to use (80% of available cores)\n",
    "#     num_cores = max(1, int(multiprocessing.cpu_count() * 0.8))\n",
    "    \n",
    "#     # Split new_data into chunks\n",
    "#     chunk_size = max(1, len(new_data) // num_cores)\n",
    "#     chunks = [new_data[i:i + chunk_size] for i in range(0, len(new_data), chunk_size)]\n",
    "    \n",
    "#     # Prepare arguments for process_chunk\n",
    "#     args = [(chunk, existing_data) for chunk in chunks]\n",
    "    \n",
    "#     # Process chunks in parallel\n",
    "#     with multiprocessing.Pool(num_cores) as pool:\n",
    "#         results = list(tqdm(pool.imap(process_chunk, args), \n",
    "#                             total=len(chunks), desc=\"Processing chunks\"))\n",
    "    \n",
    "#     # Combine results\n",
    "#     new_items = [item for sublist in results for item in sublist]\n",
    "    \n",
    "#     # Append new items to existing data\n",
    "#     updated_data = list(existing_data) + new_items\n",
    "    \n",
    "#     # Write the updated data back to the JSON file\n",
    "#     write_json(file_path, updated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9716b9d-1f5d-47d3-9a41-35f54a1455a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# if __name__ == '__main__':\n",
    "#     file_path = 'data1.json'\n",
    "#     # new_data = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]  # Example new data\n",
    "#     append_to_json(file_path, flattened_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdfeb44-183c-49df-889e-10779ce6888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_compressed_json(file_path):\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as json_file:\n",
    "            data_list_of_lists = json.load(json_file)\n",
    "        return [tuple(item) for item in data_list_of_lists]\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "def write_compressed_json(file_path, data):\n",
    "    data_list_of_lists = [list(item) for item in data]\n",
    "    with gzip.open(file_path, 'wt', encoding='utf-8') as json_file:\n",
    "        json.dump(data_list_of_lists, json_file)\n",
    "\n",
    "def process_chunk(args):\n",
    "    chunk, existing_data = args\n",
    "    return [item for item in chunk if item not in existing_data]\n",
    "\n",
    "def append_to_compressed_json(file_path, new_data):\n",
    "    # Read existing data\n",
    "    existing_data = set(read_compressed_json(file_path))\n",
    "    \n",
    "    # Determine the number of CPU cores to use (80% of available cores)\n",
    "    num_cores = max(1, int(multiprocessing.cpu_count() * 0.8))\n",
    "    \n",
    "    # Split new_data into chunks\n",
    "    chunk_size = max(1, len(new_data) // num_cores)\n",
    "    chunks = [new_data[i:i + chunk_size] for i in range(0, len(new_data), chunk_size)]\n",
    "    \n",
    "    # Prepare arguments for process_chunk\n",
    "    args = [(chunk, existing_data) for chunk in chunks]\n",
    "    \n",
    "    # Process chunks in parallel\n",
    "    with multiprocessing.Pool(num_cores) as pool:\n",
    "        results = list(tqdm(pool.imap(process_chunk, args), \n",
    "                            total=len(chunks), desc=\"Processing chunks\"))\n",
    "    \n",
    "    # Combine results\n",
    "    new_items = [item for sublist in results for item in sublist]\n",
    "    \n",
    "    # Append new items to existing data\n",
    "    updated_data = list(existing_data) + new_items\n",
    "    \n",
    "    # Write the updated data back to the compressed JSON file\n",
    "    write_compressed_json(file_path, updated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7382db55-0a98-4ce2-bc7c-0519f1c97337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 10/10 [00:57<00:00,  5.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    file_path = 'bigrams.gz'  # Note the .gz extension\n",
    "    # new_data = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]  # Example new data\n",
    "    append_to_compressed_json(file_path, flattened_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603dd7f-fa9e-49a2-ab6b-63fe98780f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
